<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data engineering with Enrique Catalá</title>
    <atom:link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <link>http://0.0.0.0:4000/</link>
    <description>Blog de Enrique Catalá, Microsoft Data Platform MVP, Ingeniero Informático centrado en Ingeniería de datos con Enrique Catalá Bañuls.</description>
    <pubDate>Tue, 21 Feb 2023 04:56:25 -0600</pubDate>
    
      <item>
        <title>Global Power Platform Boocamp 2023 Alicante</title>
        <link>http://0.0.0.0:4000/2023/02/20/Global-Power-Platform-2023-Alicante.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2023/02/20/Global-Power-Platform-2023-Alicante.html</guid>
        <description>&lt;p&gt;Tengo el placer y honor de ser ponente en el evento &lt;a href=&quot;https://www.eventbrite.es/e/entradas-global-power-platform-bootcamp-2023-488547878857&quot;&gt;Global Power Platform Bootcamp 2023
&lt;/a&gt; donde hablaré de cómo hacer BigData en una gran compañia como en la que estoy desempeñando actualmente las labores de Data Arquitect.&lt;/p&gt;

&lt;div style=&quot;text-align: center&quot;&gt;
&lt;a href=&quot;https://www.eventbrite.es/e/entradas-global-power-platform-bootcamp-2023-488547878857&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/img/posts/global_power_platform_2023/Agenda%20Power%20Platform%20Bootcamp%202023.png&quot; alt=&quot;Global Power Platform Bootcamp 2023&quot; width=&quot;70%&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Imagina que pudieras crear una arquitectura de ingesta de datos que te permitiese ser explotada en tiempo real o en batch a voluntad, preparada para equipos de IA (datos ultralimpios y versionados), que escalara sin límites y que además no tuvieras que preocuparte de limpiar los datos porque es literalmente imposible ingestar basura. ¿Te parece algo imposible? Vente que te voy a contar algunos secretos :)&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;&lt;a href=&quot;https://www.eventbrite.es/e/entradas-global-power-platform-bootcamp-2023-488547878857&quot;&gt;¿Te vienes?&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 20 Feb 2023 16:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>10 performance powerbi tips</title>
        <link>http://0.0.0.0:4000/2023/01/13/powerbi-10-tips-rendimiento.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2023/01/13/powerbi-10-tips-rendimiento.html</guid>
        <description>&lt;p&gt;Tengo el placer y honor de ser ponente en el evento &lt;a href=&quot;https://www.eventbrite.com/e/registro-powerbiespanol-virtual-conf-2023-fin-tour-power-bi-days-477181431507&quot;&gt;PowerBI Days Tour&lt;/a&gt; para impartir una sesión donde daré 10 tips de rendimiento en PowerBI.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.eventbrite.com/e/registro-powerbiespanol-virtual-conf-2023-fin-tour-power-bi-days-477181431507&quot;&gt;&lt;img src=&quot;/img/posts/powerbi-10-tips/Catala_Banuls_PowerBI_DirectQuery_10_tips_de_rendimiento_412381.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Aqui te dejo el abstract:
&lt;em&gt;En esta sesión vamos a ver 10 tips de rendimiento que no puedes perderter cuando trabajas con PowerBI en modo DirectQuery contra SQL Server&lt;/em&gt;&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;&lt;a href=&quot;https://www.eventbrite.com/e/registro-powerbiespanol-virtual-conf-2023-fin-tour-power-bi-days-477181431507&quot;&gt;¿Te vienes?&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 13 Jan 2023 16:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>Ingestando datos con cabeza</title>
        <link>http://0.0.0.0:4000/2022/12/19/ingestando-datos-con-cabeza.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/12/19/ingestando-datos-con-cabeza.html</guid>
        <description>&lt;p&gt;Hace unos dias tuve el placer y honor de ser ponente en el evento &lt;a href=&quot;https://netcoreconf.com/&quot;&gt;NetCoreConf Madrid&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Aqui te dejo el vídeo de mi sesión, espero que te guste:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/f3GID7QNY4I?start=26&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;!--end_excerpt--&gt;

&lt;p&gt;Y este es el abstract de la sesión:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Imagina que pudieras crear una arquitectura de ingesta de datos que te permitiese ser explotada en tiempo real o en batch a voluntad, preparada para equipos de IA (datos ultralimpios y versionados), que escalara sin límites y que además no tuvieras que preocuparte de limpiar los datos porque es literalmente imposible ingestar basura. ¿Te parece algo imposible? Vente que te voy a contar algunos secretos :)&lt;/em&gt;&lt;/p&gt;

</description>
        <pubDate>Mon, 19 Dec 2022 16:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>fastapi-ai-template</title>
        <link>http://0.0.0.0:4000/2022/10/24/fastapi-ai-template.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/10/24/fastapi-ai-template.html</guid>
        <description>&lt;p&gt;FastAPI is a great choice in order to deploy RESTApi with python. Its fast, easy and powerful, and something to check if you work deploying AI models for real-time inferencing in kubernetes.&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@enriquecatala/fastapi-ai-template-c46a8c5ed3fc&quot;&gt;Read more…&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Mon, 24 Oct 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Despliega tu red neuronal con FastAPI en kubernetes</title>
        <link>http://0.0.0.0:4000/2022/10/04/despliega-red-neuronal-fastapi-kubernetes.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/10/04/despliega-red-neuronal-fastapi-kubernetes.html</guid>
        <description>&lt;p&gt;Hace unos dias tuve el placer y honor de ser ponente en el evento &lt;a href=&quot;https://2022.es.pycon.org/&quot;&gt;PyCon2022&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Aqui te dejo el vídeo de mi sesión, espero que te guste:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/kTjBsHFGTBU?start=1&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;!--end_excerpt--&gt;

&lt;p&gt;Y este es el abstract de la sesión:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;FastAPI es una excelente elección a la hora de desplegar RESTApi. En esta sesión vamos a ver cómo podemos generar soluciones de despliegue de redes neuronales con FastAPI production ready. Veremos cómo hacer nuestra solución, poder depurarla usando docker y visual studio code y cómo desplegarlas con helm en nuestros clusteres kubernetes. Si te gusta el mix AI, python y kubernetes, esta es tu sesión.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/speaker-kcdspain/sentiment%20inference%20huggingface.png&quot; alt=&quot;sentiment inference huggingface&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 04 Oct 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Mesa redonda: Inteligencia Artificial. Su expansión en los negocios y en la educación</title>
        <link>http://0.0.0.0:4000/2022/10/02/mesa-redonda-ia-negocios-educacion.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/10/02/mesa-redonda-ia-negocios-educacion.html</guid>
        <description>&lt;p&gt;Aqui te dejo la grabación de la interesante mesa redonda sobre Inteligencia Artificial y su impacto en negocios y educación.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/JIhX_fC0WWY?start=1372&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;!--end_excerpt--&gt;

&lt;p&gt;Espero que te guste&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Oct 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset</title>
        <link>http://0.0.0.0:4000/2022/05/25/HADOOP_HOME-unset.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/05/25/HADOOP_HOME-unset.html</guid>
        <description>&lt;p&gt;If you want to run a spark job in windows that make use of the spark SQL pool, you need to set the HADOOP_HOME and hadoop.home.dir environment variables manually and there is a very quick and easy solution to do this.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@enriquecatala/java-io-filenotfoundexception-hadoop-home-and-hadoop-home-dir-are-unset-4004d5e05f67&quot;&gt;Continua leyendo al artículo original&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 25 May 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Git credential store in WSL</title>
        <link>http://0.0.0.0:4000/2022/05/25/Git-credential-store-in-wsl.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/05/25/Git-credential-store-in-wsl.html</guid>
        <description>&lt;p&gt;For me, Windows11 is the best shell of Linux. I´m using it in my home and work and for that reason I´m using WSL2 to run my Linux and dev station (python, scala,…), so there is a trick to avoid the problem of the Git credential store in WSL2. The trick is to configure the credential helper of the git inside WSL2 as the windows11 credential helper.&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;To do this, just run the following command in the terminal or your WSL2 shell:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; credential.helper &lt;span class=&quot;s2&quot;&gt;&quot;/mnt/c/Program&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; Files/Git/mingw64/libexec/git-core/git-credential-manager-core.exe&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, you will be storing the same credentials of windows and linux&lt;/p&gt;

</description>
        <pubDate>Wed, 25 May 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>AzureML from Docker Image</title>
        <link>http://0.0.0.0:4000/2022/01/11/azureml-from-docker-image.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/01/11/azureml-from-docker-image.html</guid>
        <description>&lt;p&gt;When you work with Azure Machine Learning, you are not required to work with Azure Machine Learning portal. Since Azure Machine Learning libraries supports to work connected with your workspace through the official library, you can benefit from containers to create an entire dev container to develop and deploy your code into Azure Machine Learning Service.&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@enriquecatala/work-locally-with-azure-machine-learning-from-docker-image-2c2e6884a3e8&quot;&gt;Read more…&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 11 Jan 2022 16:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>Speaker Codemotion 2021</title>
        <link>http://0.0.0.0:4000/2021/12/21/codemotion-speaker-deeplearning-state-of-the-art.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/12/21/codemotion-speaker-deeplearning-state-of-the-art.html</guid>
        <description>&lt;p&gt;I had the pleasure and honor to be speaker in the past &lt;a href=&quot;https://www.codemotion.com/&quot;&gt;codemotion world conference&lt;/a&gt; talking about #DeepLearning and #Azure.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tittle:&lt;/strong&gt; Applied Deep Learning state-of-the-art&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Subject:&lt;/strong&gt; In this session we will see how to do transfer learning over a state-of-the-art pre-trained model like RoBERTa to achieve our own goal in Named Entity Recognition with our own DataSet. We will take and label new data to finally feed the network trying to achieve transfer learning. Then we will make use of the new fine tuned weights and use FastAPI to deploy our new fine tuned model to kubernetes to make inference.&lt;/p&gt;

&lt;p&gt;Here is the video of my talk:&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;&lt;a href=&quot;https://talks.codemotion.com/applied-deep-learning-state-of-the-art&quot;&gt;&lt;img src=&quot;/img/posts/codemotion-2021-speaker/codemotion2021speaker.png&quot; alt=&quot;CodemotionSpeaker&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 21 Dec 2021 16:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>IOB train_test_split</title>
        <link>http://0.0.0.0:4000/2021/09/15/IOB_train_test_split.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/09/15/IOB_train_test_split.html</guid>
        <description>&lt;p&gt;When you work with text data, you often want to split it into training and test sets. This is something very usual in machine learning and also in deep learning´s natural language processing. The problem is that you have to split the data in a way that is consistent with the training and test sets, but at the same time you want to keep your data consistent.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/IOB_train_test_split/train_test.png&quot; alt=&quot;iob_train_test_split&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NOTE: img &lt;a href=&quot;https://datascience.stackexchange.com/questions/61467/clarification-on-train-test-and-val-and-how-to-use-implement-it&quot;&gt;source&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;When working with Named Entity Recognition (NER) you tipically work with IOB format. This is a very common format of tagging words in text data. But this comes with a problem…the data is stored in a very rudimentary and old way…the &lt;a href=&quot;https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)&quot;&gt;IOB format&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;IOB – Inside-Outside-Beginning&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;B-tag -&amp;gt; token is beginning of a chunk&lt;/li&gt;
  &lt;li&gt;I-tag -&amp;gt;   token is inside a chunk.&lt;/li&gt;
  &lt;li&gt;O-tag -&amp;gt; token belongs to no chunk.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So you basically have a single line per word and each sample (phrase in our case) will be delimited by an empty &lt;em&gt;“\n”&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-txt&quot;&gt;Last B-DATE
year I-DATE
, O
8.3 B-QUANTITY
million I-QUANTITY
passengers O
flew O
the O
airline O
, O
down O
4 B-PERCENT
percent I-PERCENT
from O
2007 B-DATE
. O

Everyone O
knows O
about O
ADT, B-ORG
longtime O
home O
security O
system O
provider O
in O
the B-GPE
U.S. I-GPE

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here you will find a simple example of how to split a dataset into training and test sets:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/enriquecatala/b7123540d8fae9930ed11ac982038d0c.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;
</description>
        <pubDate>Wed, 15 Sep 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>RuntimeError: Already borrowed</title>
        <link>http://0.0.0.0:4000/2021/09/15/RuntimeError-already-borrowed.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/09/15/RuntimeError-already-borrowed.html</guid>
        <description>&lt;p&gt;There was a nasty bug in &lt;a href=&quot;https://huggingface.co/&quot;&gt;huggingface’s&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/tokenizers&quot;&gt;tokenizers&lt;/a&gt; that caused a random runtime error depending on how you deal with the tokenizer when processing your neural network in a &lt;strong&gt;multi-threading&lt;/strong&gt; environment. Since I´m using kubernetes I was able to fix it by allowing the pod to be scheduled again, so I didn´t paid too much attention to it because it was related to the library itself and it was not my code the one that caused the bug.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NOTE: Details &lt;a href=&quot;https://github.com/huggingface/tokenizers/issues/537&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But then, while checking my &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview&quot;&gt;AppInsights&lt;/a&gt; I found something very bad :). I found that the bug that I thought was occurring “&lt;em&gt;sometimes&lt;/em&gt;” was happening &lt;strong&gt;all the time&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;This is the error rate of my backend with the &lt;a href=&quot;https://pypi.org/project/transformers/&quot;&gt;transformers&lt;/a&gt; version 4.6.0:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/runtimeerror-already-borrowed/buggy.png&quot; alt=&quot;x&quot; /&gt;&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;After digging a little bit I did a couple of things to improve the performance (none of them required change in my backend code):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Take myself in control of creating the whole image from scratch:
    &lt;ul&gt;
      &lt;li&gt;Change the base image from &lt;em&gt;pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime&lt;/em&gt; to &lt;em&gt;ubuntu:20.04&lt;/em&gt;
        &lt;ul&gt;
          &lt;li&gt;“Official image” is 7.5Gb&lt;/li&gt;
          &lt;li&gt;“Mine” is 2.7Gb (the one with cpu-only support)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Manually compile pytorch 1.9.0 with/without cuda support depending on my container requirements&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ensure fastapi[all]&amp;gt;=0.68.0&lt;/li&gt;
  &lt;li&gt;Ensure transformers==4.10.2
    &lt;ul&gt;
      &lt;li&gt;This was the one who fixed the bug&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And this is now, with the &lt;a href=&quot;https://pypi.org/project/transformers/&quot;&gt;transformers&lt;/a&gt; version 4.10.2:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/runtimeerror-already-borrowed/solved.png&quot; alt=&quot;x&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Near &lt;strong&gt;~3x faster and 15x less error rate&lt;/strong&gt; :)&lt;/p&gt;

&lt;p&gt;Nice!&lt;/p&gt;
</description>
        <pubDate>Wed, 15 Sep 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>How to use a specific version of az cli</title>
        <link>http://0.0.0.0:4000/2021/09/09/install-specific-version-az-cli.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/09/09/install-specific-version-az-cli.html</guid>
        <description>&lt;p&gt;There are some times when the latest version of az cli is not working. Like for example today while I was trying to debug a container issue running in Azure Container Instances.&lt;/p&gt;

&lt;p&gt;I´m getting the following error while trying to connect and check why my container is not working:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~#@❯ az container logs &lt;span class=&quot;nt&quot;&gt;--resource-group&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;InteligenciaAlertasSentinel&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; detector
The &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;failed with an unexpected error. Here is the traceback:
&lt;span class=&quot;s1&quot;&gt;'ContainerInstanceManagementClient'&lt;/span&gt; object has no attribute &lt;span class=&quot;s1&quot;&gt;'container'&lt;/span&gt;
Traceback &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;most recent call last&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/knack/cli.py&quot;&lt;/span&gt;, line 231, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;invoke
    cmd_result &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.invocation.execute&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;args&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py&quot;&lt;/span&gt;, line 657, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;execute
    raise ex
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py&quot;&lt;/span&gt;, line 720, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;_run_jobs_serially
    results.append&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self._run_job&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;expanded_arg, cmd_copy&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py&quot;&lt;/span&gt;, line 691, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;_run_job
    result &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; cmd_copy&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;params&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py&quot;&lt;/span&gt;, line 328, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;__call__
    &lt;span class=&quot;k&quot;&gt;return &lt;/span&gt;self.handler&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;args, &lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;kwargs&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/command_operation.py&quot;&lt;/span&gt;, line 112, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;handler
    client &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.client_factory&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.cli_ctx, command_args&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;self.client_factory &lt;span class=&quot;k&quot;&gt;else &lt;/span&gt;None
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/command_modules/container/_client_factory.py&quot;&lt;/span&gt;, line 18, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;cf_container
    &lt;span class=&quot;k&quot;&gt;return &lt;/span&gt;_container_instance_client_factory&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;cli_ctx&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;.container
AttributeError: &lt;span class=&quot;s1&quot;&gt;'ContainerInstanceManagementClient'&lt;/span&gt; object has no attribute &lt;span class=&quot;s1&quot;&gt;'container'&lt;/span&gt;
To open an issue, please run: &lt;span class=&quot;s1&quot;&gt;'az feedback'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems the problem is &lt;a href=&quot;https://github.com/Azure/azure-cli/issues/19475&quot;&gt;related to the version of az cli&lt;/a&gt; that I´m using (the last one while typing this post).&lt;/p&gt;

&lt;p&gt;For situations like this, i recommend you to use the &lt;a href=&quot;https://hub.docker.com/_/microsoft-azure-cli&quot;&gt;official docker repo of azure az cli&lt;/a&gt; which easily allows me to use a &lt;a href=&quot;https://mcrflowprodcentralus.data.mcr.microsoft.com/mcrprod/azure-cli?P1=1631287029&amp;amp;P2=1&amp;amp;P3=1&amp;amp;P4=4G2Xm%2FZgSoKLX2W856%2Feoxty3El5gyBaY2xnTS2KpLQ%3D&amp;amp;se=2021-09-10T15%3A17%3A09Z&amp;amp;sig=TDg2ib8Q5JU5FkGlx%2B7YQTXVQCJyPB8jPV6kIPf%2FEcc%3D&amp;amp;sp=r&amp;amp;sr=b&amp;amp;sv=2015-02-21&quot;&gt;specific version of az cli&lt;/a&gt;.&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;If you have docker installed on your machine you can install the latest version of az cli using the following command:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run &lt;span class=&quot;nt&quot;&gt;-it&lt;/span&gt; mcr.microsoft.com/azure-cli:&amp;lt;version&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;NOTE: last version working is 2.27.2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And that´s it!, as easy as that :)&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Sep 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Speaker netCoreConf 2021</title>
        <link>http://0.0.0.0:4000/2021/08/31/Speaker-netCoreConf-2021.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/08/31/Speaker-netCoreConf-2021.html</guid>
        <description>&lt;p&gt;Tengo el placer y honor de ser ponente en el próximo evento &lt;a href=&quot;https://netcoreconf.com/&quot;&gt;#netCoreConf&lt;/a&gt; que tendrá lugar en los dias 9 y 10 de Octubre 2021.&lt;/p&gt;

&lt;p&gt;En mi sesión voy a hablar durante 55m de &lt;strong&gt;Deeplearning state-of-the-art aplicado&lt;/strong&gt; donde veremos cómo podemos realizar transfer learning sobre un modelo transformer state of the art como RoBERTa para Named Entity Recognition con nuestro propio dataset, que acabaremos desplegando en kubernetes para poder hacer inferencia como nuestra propia API de AI con FastAPI. La idea es que os quedeis con una alternativa diferente de bajo coste aprovechando Azure VM y AKS para desplegar los modelos que vuestros cientificos de datos acaban dejando típicamente en un python notebook :)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Jugaremos con Spacy, huggingface, pytorch, python, FastAPI, AKS y terraform :)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/speaker-codemotion-2021-2/card.jpg&quot; alt=&quot;card&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 31 Aug 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>How to release memory consumed by vmmem WSL2</title>
        <link>http://0.0.0.0:4000/2021/07/26/release-memory-consumed-by-vmmem.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/07/26/release-memory-consumed-by-vmmem.html</guid>
        <description>&lt;p&gt;There is a bug in WSL2 that causes the memory consumption of the vmmem process to not to be released. Right now, the version of WSL2 and windows i´m using is Windows 10 19043.1110 (21H1) and it´s still present.&lt;/p&gt;

&lt;p&gt;This is what you can see when the error happens:&lt;/p&gt;

&lt;p&gt;1) You have your WSL2 images stopped:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/vmmem-taking-too-much-memory/vmmem2.png&quot; alt=&quot;vmmem1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2) There is a lot of memory ussage from the vmmem process:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/vmmem-taking-too-much-memory/vmmem1.png&quot; alt=&quot;vmmem1&quot; /&gt;&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;The solution for this is to simply stop the vmmem process:&lt;/p&gt;

&lt;div class=&quot;language-powershell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;wsl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;--shutdown&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Et voila :)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/vmmem-taking-too-much-memory/vmmem3.png&quot; alt=&quot;vmmem3&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 26 Jul 2021 17:00:00 -0500</pubDate>
      </item>
    
  </channel>
</rss>
