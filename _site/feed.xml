<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data engineering with Enrique Catalá</title>
    <atom:link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <link>http://0.0.0.0:4000/</link>
    <description>Blog de Enrique Catalá, Microsoft Data Platform MVP, Ingeniero Informático centrado en Ingeniería de datos con Enrique Catalá Bañuls.</description>
    <pubDate>Tue, 20 Dec 2022 11:07:28 -0600</pubDate>
    
      <item>
        <title>Ingestando datos con cabeza</title>
        <link>http://0.0.0.0:4000/2022/12/19/ingestando-datos-con-cabeza.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/12/19/ingestando-datos-con-cabeza.html</guid>
        <description>&lt;p&gt;Hace unos dias tuve el placer y honor de ser ponente en el evento &lt;a href=&quot;https://netcoreconf.com/&quot;&gt;NetCoreConf Madrid&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Aqui te dejo el vídeo de mi sesión, espero que te guste:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/f3GID7QNY4I?start=26&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;!--end_excerpt--&gt;

&lt;p&gt;Y este es el abstract de la sesión:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Imagina que pudieras crear una arquitectura de ingesta de datos que te permitiese ser explotada en tiempo real o en batch a voluntad, preparada para equipos de IA (datos ultralimpios y versionados), que escalara sin límites y que además no tuvieras que preocuparte de limpiar los datos porque es literalmente imposible ingestar basura. ¿Te parece algo imposible? Vente que te voy a contar algunos secretos :)&lt;/em&gt;&lt;/p&gt;

</description>
        <pubDate>Mon, 19 Dec 2022 16:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>fastapi-ai-template</title>
        <link>http://0.0.0.0:4000/2022/10/24/fastapi-ai-template.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/10/24/fastapi-ai-template.html</guid>
        <description>&lt;p&gt;FastAPI is a great choice in order to deploy RESTApi with python. Its fast, easy and powerful, and something to check if you work deploying AI models for real-time inferencing in kubernetes.&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@enriquecatala/fastapi-ai-template-c46a8c5ed3fc&quot;&gt;Read more…&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Mon, 24 Oct 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Despliega tu red neuronal con FastAPI en kubernetes</title>
        <link>http://0.0.0.0:4000/2022/10/04/despliega-red-neuronal-fastapi-kubernetes.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/10/04/despliega-red-neuronal-fastapi-kubernetes.html</guid>
        <description>&lt;p&gt;Hace unos dias tuve el placer y honor de ser ponente en el evento &lt;a href=&quot;https://2022.es.pycon.org/&quot;&gt;PyCon2022&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Aqui te dejo el vídeo de mi sesión, espero que te guste:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/kTjBsHFGTBU?start=1&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;!--end_excerpt--&gt;

&lt;p&gt;Y este es el abstract de la sesión:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;FastAPI es una excelente elección a la hora de desplegar RESTApi. En esta sesión vamos a ver cómo podemos generar soluciones de despliegue de redes neuronales con FastAPI production ready. Veremos cómo hacer nuestra solución, poder depurarla usando docker y visual studio code y cómo desplegarlas con helm en nuestros clusteres kubernetes. Si te gusta el mix AI, python y kubernetes, esta es tu sesión.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/speaker-kcdspain/sentiment%20inference%20huggingface.png&quot; alt=&quot;sentiment inference huggingface&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 04 Oct 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Mesa redonda: Inteligencia Artificial. Su expansión en los negocios y en la educación</title>
        <link>http://0.0.0.0:4000/2022/10/02/mesa-redonda-ia-negocios-educacion.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/10/02/mesa-redonda-ia-negocios-educacion.html</guid>
        <description>&lt;p&gt;Aqui te dejo la grabación de la interesante mesa redonda sobre Inteligencia Artificial y su impacto en negocios y educación.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/JIhX_fC0WWY?start=1372&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;!--end_excerpt--&gt;

&lt;p&gt;Espero que te guste&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Oct 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset</title>
        <link>http://0.0.0.0:4000/2022/05/25/HADOOP_HOME-unset.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/05/25/HADOOP_HOME-unset.html</guid>
        <description>&lt;p&gt;If you want to run a spark job in windows that make use of the spark SQL pool, you need to set the HADOOP_HOME and hadoop.home.dir environment variables manually and there is a very quick and easy solution to do this.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@enriquecatala/java-io-filenotfoundexception-hadoop-home-and-hadoop-home-dir-are-unset-4004d5e05f67&quot;&gt;Continua leyendo al artículo original&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 25 May 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Git credential store in WSL</title>
        <link>http://0.0.0.0:4000/2022/05/25/Git-credential-store-in-wsl.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/05/25/Git-credential-store-in-wsl.html</guid>
        <description>&lt;p&gt;For me, Windows11 is the best shell of Linux. I´m using it in my home and work and for that reason I´m using WSL2 to run my Linux and dev station (python, scala,…), so there is a trick to avoid the problem of the Git credential store in WSL2. The trick is to configure the credential helper of the git inside WSL2 as the windows11 credential helper.&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;To do this, just run the following command in the terminal or your WSL2 shell:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; credential.helper &lt;span class=&quot;s2&quot;&gt;&quot;/mnt/c/Program&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; Files/Git/mingw64/libexec/git-core/git-credential-manager-core.exe&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, you will be storing the same credentials of windows and linux&lt;/p&gt;

</description>
        <pubDate>Wed, 25 May 2022 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>AzureML from Docker Image</title>
        <link>http://0.0.0.0:4000/2022/01/11/azureml-from-docker-image.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2022/01/11/azureml-from-docker-image.html</guid>
        <description>&lt;p&gt;When you work with Azure Machine Learning, you are not required to work with Azure Machine Learning portal. Since Azure Machine Learning libraries supports to work connected with your workspace through the official library, you can benefit from containers to create an entire dev container to develop and deploy your code into Azure Machine Learning Service.&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@enriquecatala/work-locally-with-azure-machine-learning-from-docker-image-2c2e6884a3e8&quot;&gt;Read more…&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 11 Jan 2022 16:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>Speaker Codemotion 2021</title>
        <link>http://0.0.0.0:4000/2021/12/21/codemotion-speaker-deeplearning-state-of-the-art.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/12/21/codemotion-speaker-deeplearning-state-of-the-art.html</guid>
        <description>&lt;p&gt;I had the pleasure and honor to be speaker in the past &lt;a href=&quot;https://www.codemotion.com/&quot;&gt;codemotion world conference&lt;/a&gt; talking about #DeepLearning and #Azure.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tittle:&lt;/strong&gt; Applied Deep Learning state-of-the-art&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Subject:&lt;/strong&gt; In this session we will see how to do transfer learning over a state-of-the-art pre-trained model like RoBERTa to achieve our own goal in Named Entity Recognition with our own DataSet. We will take and label new data to finally feed the network trying to achieve transfer learning. Then we will make use of the new fine tuned weights and use FastAPI to deploy our new fine tuned model to kubernetes to make inference.&lt;/p&gt;

&lt;p&gt;Here is the video of my talk:&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;&lt;a href=&quot;https://talks.codemotion.com/applied-deep-learning-state-of-the-art&quot;&gt;&lt;img src=&quot;/img/posts/codemotion-2021-speaker/codemotion2021speaker.png&quot; alt=&quot;CodemotionSpeaker&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 21 Dec 2021 16:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>IOB train_test_split</title>
        <link>http://0.0.0.0:4000/2021/09/15/IOB_train_test_split.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/09/15/IOB_train_test_split.html</guid>
        <description>&lt;p&gt;When you work with text data, you often want to split it into training and test sets. This is something very usual in machine learning and also in deep learning´s natural language processing. The problem is that you have to split the data in a way that is consistent with the training and test sets, but at the same time you want to keep your data consistent.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/IOB_train_test_split/train_test.png&quot; alt=&quot;iob_train_test_split&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NOTE: img &lt;a href=&quot;https://datascience.stackexchange.com/questions/61467/clarification-on-train-test-and-val-and-how-to-use-implement-it&quot;&gt;source&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;When working with Named Entity Recognition (NER) you tipically work with IOB format. This is a very common format of tagging words in text data. But this comes with a problem…the data is stored in a very rudimentary and old way…the &lt;a href=&quot;https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)&quot;&gt;IOB format&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;IOB – Inside-Outside-Beginning&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;B-tag -&amp;gt; token is beginning of a chunk&lt;/li&gt;
  &lt;li&gt;I-tag -&amp;gt;   token is inside a chunk.&lt;/li&gt;
  &lt;li&gt;O-tag -&amp;gt; token belongs to no chunk.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So you basically have a single line per word and each sample (phrase in our case) will be delimited by an empty &lt;em&gt;“\n”&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-txt&quot;&gt;Last B-DATE
year I-DATE
, O
8.3 B-QUANTITY
million I-QUANTITY
passengers O
flew O
the O
airline O
, O
down O
4 B-PERCENT
percent I-PERCENT
from O
2007 B-DATE
. O

Everyone O
knows O
about O
ADT, B-ORG
longtime O
home O
security O
system O
provider O
in O
the B-GPE
U.S. I-GPE

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here you will find a simple example of how to split a dataset into training and test sets:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/enriquecatala/b7123540d8fae9930ed11ac982038d0c.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;
</description>
        <pubDate>Wed, 15 Sep 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>RuntimeError: Already borrowed</title>
        <link>http://0.0.0.0:4000/2021/09/15/RuntimeError-already-borrowed.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/09/15/RuntimeError-already-borrowed.html</guid>
        <description>&lt;p&gt;There was a nasty bug in &lt;a href=&quot;https://huggingface.co/&quot;&gt;huggingface’s&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/tokenizers&quot;&gt;tokenizers&lt;/a&gt; that caused a random runtime error depending on how you deal with the tokenizer when processing your neural network in a &lt;strong&gt;multi-threading&lt;/strong&gt; environment. Since I´m using kubernetes I was able to fix it by allowing the pod to be scheduled again, so I didn´t paid too much attention to it because it was related to the library itself and it was not my code the one that caused the bug.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NOTE: Details &lt;a href=&quot;https://github.com/huggingface/tokenizers/issues/537&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But then, while checking my &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview&quot;&gt;AppInsights&lt;/a&gt; I found something very bad :). I found that the bug that I thought was occurring “&lt;em&gt;sometimes&lt;/em&gt;” was happening &lt;strong&gt;all the time&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;This is the error rate of my backend with the &lt;a href=&quot;https://pypi.org/project/transformers/&quot;&gt;transformers&lt;/a&gt; version 4.6.0:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/runtimeerror-already-borrowed/buggy.png&quot; alt=&quot;x&quot; /&gt;&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;After digging a little bit I did a couple of things to improve the performance (none of them required change in my backend code):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Take myself in control of creating the whole image from scratch:
    &lt;ul&gt;
      &lt;li&gt;Change the base image from &lt;em&gt;pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime&lt;/em&gt; to &lt;em&gt;ubuntu:20.04&lt;/em&gt;
        &lt;ul&gt;
          &lt;li&gt;“Official image” is 7.5Gb&lt;/li&gt;
          &lt;li&gt;“Mine” is 2.7Gb (the one with cpu-only support)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Manually compile pytorch 1.9.0 with/without cuda support depending on my container requirements&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ensure fastapi[all]&amp;gt;=0.68.0&lt;/li&gt;
  &lt;li&gt;Ensure transformers==4.10.2
    &lt;ul&gt;
      &lt;li&gt;This was the one who fixed the bug&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And this is now, with the &lt;a href=&quot;https://pypi.org/project/transformers/&quot;&gt;transformers&lt;/a&gt; version 4.10.2:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/runtimeerror-already-borrowed/solved.png&quot; alt=&quot;x&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Near &lt;strong&gt;~3x faster and 15x less error rate&lt;/strong&gt; :)&lt;/p&gt;

&lt;p&gt;Nice!&lt;/p&gt;
</description>
        <pubDate>Wed, 15 Sep 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>How to use a specific version of az cli</title>
        <link>http://0.0.0.0:4000/2021/09/09/install-specific-version-az-cli.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/09/09/install-specific-version-az-cli.html</guid>
        <description>&lt;p&gt;There are some times when the latest version of az cli is not working. Like for example today while I was trying to debug a container issue running in Azure Container Instances.&lt;/p&gt;

&lt;p&gt;I´m getting the following error while trying to connect and check why my container is not working:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~#@❯ az container logs &lt;span class=&quot;nt&quot;&gt;--resource-group&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;InteligenciaAlertasSentinel&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; detector
The &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;failed with an unexpected error. Here is the traceback:
&lt;span class=&quot;s1&quot;&gt;'ContainerInstanceManagementClient'&lt;/span&gt; object has no attribute &lt;span class=&quot;s1&quot;&gt;'container'&lt;/span&gt;
Traceback &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;most recent call last&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/knack/cli.py&quot;&lt;/span&gt;, line 231, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;invoke
    cmd_result &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.invocation.execute&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;args&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py&quot;&lt;/span&gt;, line 657, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;execute
    raise ex
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py&quot;&lt;/span&gt;, line 720, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;_run_jobs_serially
    results.append&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self._run_job&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;expanded_arg, cmd_copy&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py&quot;&lt;/span&gt;, line 691, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;_run_job
    result &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; cmd_copy&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;params&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/__init__.py&quot;&lt;/span&gt;, line 328, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;__call__
    &lt;span class=&quot;k&quot;&gt;return &lt;/span&gt;self.handler&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;args, &lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;kwargs&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/core/commands/command_operation.py&quot;&lt;/span&gt;, line 112, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;handler
    client &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.client_factory&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.cli_ctx, command_args&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;self.client_factory &lt;span class=&quot;k&quot;&gt;else &lt;/span&gt;None
  File &lt;span class=&quot;s2&quot;&gt;&quot;/opt/az/lib/python3.6/site-packages/azure/cli/command_modules/container/_client_factory.py&quot;&lt;/span&gt;, line 18, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;cf_container
    &lt;span class=&quot;k&quot;&gt;return &lt;/span&gt;_container_instance_client_factory&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;cli_ctx&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;.container
AttributeError: &lt;span class=&quot;s1&quot;&gt;'ContainerInstanceManagementClient'&lt;/span&gt; object has no attribute &lt;span class=&quot;s1&quot;&gt;'container'&lt;/span&gt;
To open an issue, please run: &lt;span class=&quot;s1&quot;&gt;'az feedback'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems the problem is &lt;a href=&quot;https://github.com/Azure/azure-cli/issues/19475&quot;&gt;related to the version of az cli&lt;/a&gt; that I´m using (the last one while typing this post).&lt;/p&gt;

&lt;p&gt;For situations like this, i recommend you to use the &lt;a href=&quot;https://hub.docker.com/_/microsoft-azure-cli&quot;&gt;official docker repo of azure az cli&lt;/a&gt; which easily allows me to use a &lt;a href=&quot;https://mcrflowprodcentralus.data.mcr.microsoft.com/mcrprod/azure-cli?P1=1631287029&amp;amp;P2=1&amp;amp;P3=1&amp;amp;P4=4G2Xm%2FZgSoKLX2W856%2Feoxty3El5gyBaY2xnTS2KpLQ%3D&amp;amp;se=2021-09-10T15%3A17%3A09Z&amp;amp;sig=TDg2ib8Q5JU5FkGlx%2B7YQTXVQCJyPB8jPV6kIPf%2FEcc%3D&amp;amp;sp=r&amp;amp;sr=b&amp;amp;sv=2015-02-21&quot;&gt;specific version of az cli&lt;/a&gt;.&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;If you have docker installed on your machine you can install the latest version of az cli using the following command:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run &lt;span class=&quot;nt&quot;&gt;-it&lt;/span&gt; mcr.microsoft.com/azure-cli:&amp;lt;version&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;NOTE: last version working is 2.27.2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And that´s it!, as easy as that :)&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Sep 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Speaker netCoreConf 2021</title>
        <link>http://0.0.0.0:4000/2021/08/31/Speaker-netCoreConf-2021.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/08/31/Speaker-netCoreConf-2021.html</guid>
        <description>&lt;p&gt;Tengo el placer y honor de ser ponente en el próximo evento &lt;a href=&quot;https://netcoreconf.com/&quot;&gt;#netCoreConf&lt;/a&gt; que tendrá lugar en los dias 9 y 10 de Octubre 2021.&lt;/p&gt;

&lt;p&gt;En mi sesión voy a hablar durante 55m de &lt;strong&gt;Deeplearning state-of-the-art aplicado&lt;/strong&gt; donde veremos cómo podemos realizar transfer learning sobre un modelo transformer state of the art como RoBERTa para Named Entity Recognition con nuestro propio dataset, que acabaremos desplegando en kubernetes para poder hacer inferencia como nuestra propia API de AI con FastAPI. La idea es que os quedeis con una alternativa diferente de bajo coste aprovechando Azure VM y AKS para desplegar los modelos que vuestros cientificos de datos acaban dejando típicamente en un python notebook :)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Jugaremos con Spacy, huggingface, pytorch, python, FastAPI, AKS y terraform :)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/speaker-codemotion-2021-2/card.jpg&quot; alt=&quot;card&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 31 Aug 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>How to release memory consumed by vmmem WSL2</title>
        <link>http://0.0.0.0:4000/2021/07/26/release-memory-consumed-by-vmmem.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/07/26/release-memory-consumed-by-vmmem.html</guid>
        <description>&lt;p&gt;There is a bug in WSL2 that causes the memory consumption of the vmmem process to not to be released. Right now, the version of WSL2 and windows i´m using is Windows 10 19043.1110 (21H1) and it´s still present.&lt;/p&gt;

&lt;p&gt;This is what you can see when the error happens:&lt;/p&gt;

&lt;p&gt;1) You have your WSL2 images stopped:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/vmmem-taking-too-much-memory/vmmem2.png&quot; alt=&quot;vmmem1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2) There is a lot of memory ussage from the vmmem process:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/vmmem-taking-too-much-memory/vmmem1.png&quot; alt=&quot;vmmem1&quot; /&gt;&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;The solution for this is to simply stop the vmmem process:&lt;/p&gt;

&lt;div class=&quot;language-powershell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;wsl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;--shutdown&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Et voila :)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/vmmem-taking-too-much-memory/vmmem3.png&quot; alt=&quot;vmmem3&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 26 Jul 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Cómo desplegar redes neuronales en kubernetes con hardware CUDA</title>
        <link>http://0.0.0.0:4000/2021/07/22/como-desplegar-redes-neuronales-kubernetes-hw-cuda.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/07/22/como-desplegar-redes-neuronales-kubernetes-hw-cuda.html</guid>
        <description>&lt;p&gt;Hace unos dias tuve el placer y honor de ser ponente en el evento &lt;a href=&quot;https://community.cncf.io/events/details/cncf-kcd-spain-presents-kubernetes-community-days-spain/&quot;&gt;Kubernetes Community Days Spain&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Aqui te dejo el vídeo de mi sesión, espero que te guste:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/-MaFzqWaRyM?start=14&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;!--end_excerpt--&gt;

&lt;p&gt;Y este es el abstract de la sesión:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Kubernetes es la plataforma ideal para desplegar modelos deeplearning. Nos permite escalar nuestas redes en multiples pods y nodos, añadir soporte para hardware específico facilmente y además poder utilizar cualquier nube ya sea de forma pública o privada para nuestros modelos. En esta sesión vamos a ver cómo podemos montar nuestros propios contenedores con FastAPI, desplegarlos en nuestro propio cluster, cómo consumirlos y cómo preparar nuestra propia infraestructura para producción.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/speaker-kcdspain/sentiment%20inference%20huggingface.png&quot; alt=&quot;sentiment inference huggingface&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 22 Jul 2021 17:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Configurar conda para desarrollo con python</title>
        <link>http://0.0.0.0:4000/2021/05/14/Configurar-conda-para-desarrollo-con-python.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2021/05/14/Configurar-conda-para-desarrollo-con-python.html</guid>
        <description>&lt;p&gt;Algún dia me animaré a hacer algun post/video sobre cómo hago dev y debug sobre python, pero mientras tanto, valga este post para recodar cómo preparar nuestro PC para desarrollo con python. Conda es un excelente entorno para data science, que incluye de serie y de forma gratuita 2 cosas super-utiles como son el editor “Spider” y la gestión de entornos muy cómoda.&lt;/p&gt;

&lt;p&gt;En este post vamos a ver rápidamente cómo configurar nuestro entorno python con conda para desarrollo data science sobre &lt;a href=&quot;#windows&quot;&gt;Windows&lt;/a&gt; y sobre &lt;a href=&quot;#linux&quot;&gt;Linux&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/configurar-conda/Anaconda.png&quot; alt=&quot;anaconda gui&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Para configurarlo te propongo:&lt;/p&gt;

&lt;!--end_excerpt--&gt;

&lt;h1 id=&quot;windows&quot;&gt;Windows&lt;/h1&gt;

&lt;h2 id=&quot;instalación&quot;&gt;Instalación&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Instala &lt;a href=&quot;https://www.anaconda.com/products/individual&quot;&gt;anaconda&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Abre anaconda prompt&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/configurar-conda/condaprompt.png&quot; alt=&quot;anaconda prompt&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lanza &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;where conda&lt;/code&gt; y copia la ubicación de su ejecutable&lt;/li&gt;
  &lt;li&gt;Abre “Advanced system settings”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/configurar-conda/advanced-system-settings.png&quot; alt=&quot;advanced system settings&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Añade a tu PATH el path de conda que te salga, que en mi caso es:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;C:&lt;span class=&quot;se&quot;&gt;\U&lt;/span&gt;sers&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriq&lt;span class=&quot;se&quot;&gt;\a&lt;/span&gt;naconda3&lt;span class=&quot;se&quot;&gt;\L&lt;/span&gt;ibrary&lt;span class=&quot;se&quot;&gt;\b&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;in
&lt;/span&gt;C:&lt;span class=&quot;se&quot;&gt;\U&lt;/span&gt;sers&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriq&lt;span class=&quot;se&quot;&gt;\a&lt;/span&gt;naconda3&lt;span class=&quot;se&quot;&gt;\S&lt;/span&gt;cripts
C:&lt;span class=&quot;se&quot;&gt;\U&lt;/span&gt;sers&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriq&lt;span class=&quot;se&quot;&gt;\a&lt;/span&gt;naconda3&lt;span class=&quot;se&quot;&gt;\c&lt;/span&gt;ondabin
C:&lt;span class=&quot;se&quot;&gt;\U&lt;/span&gt;sers&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriq&lt;span class=&quot;se&quot;&gt;\a&lt;/span&gt;naconda3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ya deberia funcionar lanzando &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conda --version&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/configurar-conda/conda-version.png&quot; alt=&quot;conda-version&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Asegurate que tienes la última version de anaconda &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conda update anaconda&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;❯ conda update anaconda
Collecting package metadata &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;current_repodata.json&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: &lt;span class=&quot;k&quot;&gt;done
&lt;/span&gt;Solving environment: &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# All requested packages already installed.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Actualiza spider a la version 5&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;spider&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;5.0.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;aislar-entornos-de-trabajo&quot;&gt;Aislar entornos de trabajo&lt;/h2&gt;

&lt;p&gt;Es mas que interesante crear entornos de trabajo para cada proyecto. Esto es útil por ejemplo para poder tener diferentes versiones de python/librerias que puedan ser incompatibles entre ellas.&lt;/p&gt;

&lt;p&gt;Por ejemplo, si quisiéramos crearnos un entorno para trabajar con la IA &lt;a href=&quot;https://github.com/EleutherAI/gpt-neo&quot;&gt;GPT-Neo&lt;/a&gt;, que en el momento de escribir estas líneas está únicamente disponible en la rama main de &lt;a href=&quot;https://huggingface.co/&quot;&gt;huggingface&lt;/a&gt; (no en su paquete oficial todavía)&lt;/p&gt;

&lt;h3 id=&quot;crear-un-entorno&quot;&gt;Crear un entorno&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda create &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; gptneo &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.8.8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Cuyo output…&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;❯ conda create &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; gptneo &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.8.8
Collecting package metadata &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;current_repodata.json&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: &lt;span class=&quot;k&quot;&gt;done
&lt;/span&gt;Solving environment: &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## Package Plan ##&lt;/span&gt;

  environment location: C:&lt;span class=&quot;se&quot;&gt;\U&lt;/span&gt;sers&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriq&lt;span class=&quot;se&quot;&gt;\a&lt;/span&gt;naconda3&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nvs&lt;span class=&quot;se&quot;&gt;\g&lt;/span&gt;ptneo

  added / updated specs:
    - &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.8.8


The following NEW packages will be INSTALLED:

  ca-certificates    pkgs/main/win-64::ca-certificates-2021.4.13-haa95532_1
  certifi            pkgs/main/win-64::certifi-2020.12.5-py38haa95532_0
  openssl            pkgs/main/win-64::openssl-1.1.1k-h2bbff1b_0
  pip                pkgs/main/win-64::pip-21.0.1-py38haa95532_0
  python             pkgs/main/win-64::python-3.8.8-hdbf39b2_5
  setuptools         pkgs/main/win-64::setuptools-52.0.0-py38haa95532_0
  sqlite             pkgs/main/win-64::sqlite-3.35.4-h2bbff1b_0
  vc                 pkgs/main/win-64::vc-14.2-h21ff451_1
  vs2015_runtime     pkgs/main/win-64::vs2015_runtime-14.27.29016-h5e58377_2
  wheel              pkgs/main/noarch::wheel-0.36.2-pyhd3eb1b0_0
  wincertstore       pkgs/main/win-64::wincertstore-0.2-py38_0


Proceed &lt;span class=&quot;o&quot;&gt;([&lt;/span&gt;y]/n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;? y

Preparing transaction: &lt;span class=&quot;k&quot;&gt;done
&lt;/span&gt;Verifying transaction: &lt;span class=&quot;k&quot;&gt;done
&lt;/span&gt;Executing transaction: &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# To activate this environment, use&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#     $ conda activate gptneo&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# To deactivate an active environment, use&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#     $ conda deactivate&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;activar-el-entorno&quot;&gt;Activar el entorno&lt;/h3&gt;

&lt;p&gt;Para activar el entorno por línea de comandos puedes lanzar &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conda activate gptneo&lt;/code&gt;, pero si lo que quieres es desde code, hacer el cambio…la opción mas facil sería lanzar &lt;em&gt;F1-&amp;gt;Python: select interpreter&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/configurar-conda/select-interpreter.png&quot; alt=&quot;select interpreter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;que como verás, ya automáticamente detecta el nuevo entorno:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/configurar-conda/gptneo.png&quot; alt=&quot;python gptneo&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;instalar-paquetes-en-el-entorno&quot;&gt;Instalar paquetes en el entorno&lt;/h3&gt;

&lt;p&gt;Una vez asegurados en el entorno de trabajo, ya podemos instalar nuestros paquetes con normalidad. En mi caso voy a desplegar la rama main de &lt;a href=&quot;https://github.com/huggingface/transformers&quot;&gt;git de huggingface&lt;/a&gt;, para poder acceder a las mejoras Transformer con las que poder desplegar una AI con &lt;a href=&quot;https://huggingface.co/EleutherAI/gpt-neo-2.7B&quot;&gt;GPTNeo 2.7B&lt;/a&gt; (lo mas parecido ahora mismo a la versión light de &lt;a href=&quot;https://arxiv.org/abs/2005.14165&quot;&gt;GPT-3&lt;/a&gt;)&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;base&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; D:&lt;span class=&quot;se&quot;&gt;\g&lt;/span&gt;it&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriquecatala.github.io&amp;gt;conda activate gptneo
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;gptneo&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; D:&lt;span class=&quot;se&quot;&gt;\g&lt;/span&gt;it&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriquecatala.github.io&amp;gt;pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;git+https://github.com/huggingface/transformers@master
Collecting git+https://github.com/huggingface/transformers@master
  Cloning https://github.com/huggingface/transformers &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;to revision master&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; to c:&lt;span class=&quot;se&quot;&gt;\u&lt;/span&gt;sers&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriq&lt;span class=&quot;se&quot;&gt;\a&lt;/span&gt;ppdata&lt;span class=&quot;se&quot;&gt;\l&lt;/span&gt;ocal&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;emp&lt;span class=&quot;se&quot;&gt;\p&lt;/span&gt;ip-req-build-2ebx9m9g
  Running &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;git clone &lt;span class=&quot;nt&quot;&gt;-q&lt;/span&gt; https://github.com/huggingface/transformers &lt;span class=&quot;s1&quot;&gt;'C:\Users\enriq\AppData\Local\Temp\pip-req-build-2ebx9m9g'&lt;/span&gt;
  Installing build dependencies ... &lt;span class=&quot;k&quot;&gt;done
  &lt;/span&gt;Getting requirements to build wheel ... &lt;span class=&quot;k&quot;&gt;done
    &lt;/span&gt;Preparing wheel metadata ... &lt;span class=&quot;k&quot;&gt;done
&lt;/span&gt;Collecting sacremoses
  Downloading sacremoses-0.0.45-py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;895 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 895 kB 6.8 MB/s
Collecting huggingface-hub&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;0.0.8
  Downloading huggingface_hub-0.0.8-py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;34 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Collecting filelock
  Downloading filelock-3.0.12-py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;7.6 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Collecting tqdm&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4.27
  Downloading tqdm-4.60.0-py2.py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;75 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 75 kB 5.1 MB/s
Collecting packaging
  Downloading packaging-20.9-py2.py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;40 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 40 kB 2.7 MB/s
Collecting numpy&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.17
  Downloading numpy-1.20.3-cp38-cp38-win_amd64.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;13.7 MB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 13.7 MB ...
Collecting requests
  Downloading requests-2.25.1-py2.py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;61 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 61 kB 3.8 MB/s
Collecting regex!&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2019.12.17
  Downloading regex-2021.4.4-cp38-cp38-win_amd64.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;270 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 270 kB ...
Collecting tokenizers&amp;lt;0.11,&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.10.1
  Downloading tokenizers-0.10.2-cp38-cp38-win_amd64.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2.0 MB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 2.0 MB 6.8 MB/s
Collecting pyparsing&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2.0.2
  Downloading pyparsing-2.4.7-py2.py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;67 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 67 kB 2.8 MB/s
Collecting idna&amp;lt;3,&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2.5
  Downloading idna-2.10-py2.py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;58 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 58 kB ...
Collecting chardet&amp;lt;5,&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.0.2
  Downloading chardet-4.0.0-py2.py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;178 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 178 kB ...
Collecting urllib3&amp;lt;1.27,&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.21.1
  Downloading urllib3-1.26.4-py2.py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;153 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 153 kB ...
Requirement already satisfied: certifi&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2017.4.17 &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;c:&lt;span class=&quot;se&quot;&gt;\u&lt;/span&gt;sers&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriq&lt;span class=&quot;se&quot;&gt;\a&lt;/span&gt;naconda3&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nvs&lt;span class=&quot;se&quot;&gt;\g&lt;/span&gt;ptneo&lt;span class=&quot;se&quot;&gt;\l&lt;/span&gt;ib&lt;span class=&quot;se&quot;&gt;\s&lt;/span&gt;ite-packages &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;from requests-&amp;gt;transformers&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;4.7.0.dev0&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2020.12.5&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Collecting six
  Downloading six-1.16.0-py2.py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;11 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Collecting joblib
  Downloading joblib-1.0.1-py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;303 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 303 kB 6.4 MB/s
Collecting click
  Downloading click-8.0.0-py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;96 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
     |████████████████████████████████| 96 kB 6.4 MB/s
Collecting colorama
  Downloading colorama-0.4.4-py2.py3-none-any.whl &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;16 kB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Building wheels &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;collected packages: transformers
  Building wheel &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;transformers &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;PEP 517&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; ... &lt;span class=&quot;k&quot;&gt;done
  &lt;/span&gt;Created wheel &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;transformers: &lt;span class=&quot;nv&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;transformers-4.7.0.dev0-py3-none-any.whl &lt;span class=&quot;nv&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2259729 &lt;span class=&quot;nv&quot;&gt;sha256&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;45d5f23c6d779450d66f26a1d9956684a0e88a0689b36b7e4b616dc6690149b2
  Stored &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;directory: C:&lt;span class=&quot;se&quot;&gt;\U&lt;/span&gt;sers&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;nriq&lt;span class=&quot;se&quot;&gt;\A&lt;/span&gt;ppData&lt;span class=&quot;se&quot;&gt;\L&lt;/span&gt;ocal&lt;span class=&quot;se&quot;&gt;\T&lt;/span&gt;emp&lt;span class=&quot;se&quot;&gt;\p&lt;/span&gt;ip-ephem-wheel-cache-8am4pg42&lt;span class=&quot;se&quot;&gt;\w&lt;/span&gt;heels&lt;span class=&quot;se&quot;&gt;\2&lt;/span&gt;9&lt;span class=&quot;se&quot;&gt;\9&lt;/span&gt;7&lt;span class=&quot;se&quot;&gt;\b&lt;/span&gt;a&lt;span class=&quot;se&quot;&gt;\e&lt;/span&gt;da99aa62c8a9414a8754b0b94ed3ae80559d7c8293929140f
Successfully built transformers
Installing collected packages: urllib3, idna, colorama, chardet, tqdm, six, requests, regex, pyparsing, joblib, filelock, click, tokenizers, sacremoses, packaging, numpy, huggingface-hub, transformers
Successfully installed chardet-4.0.0 click-8.0.0 colorama-0.4.4 filelock-3.0.12 huggingface-hub-0.0.8 idna-2.10 joblib-1.0.1 
numpy-1.20.3 packaging-20.9 pyparsing-2.4.7 regex-2021.4.4 requests-2.25.1 sacremoses-0.0.45 six-1.16.0 tokenizers-0.10.2 tqdm-4.60.0 transformers-4.7.0.dev0 urllib3-1.26.4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Y ya está, tenemos el entorno nuevo, con huggigface transformers utilizando la última versión disponible estable, que va por delante del propio paquete oficial huggingface (que es lo que quería enseñarte yo en este caso de ejemplo)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NOTA: Recuerda que cada entorno está totalmente aislado del resto, y esto implica que incluso el ide Spyder no estará disponible en nuestro nuevo environment, lo que quiere decir que lo tendrás que instalar ahi tambien :)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;spider&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;5.0.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;linux&quot;&gt;Linux&lt;/h1&gt;

&lt;p&gt;En el caso de linux, pues se puede scriptar mas facilmente para variar :)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/posts/configurar-conda/conda-ubuntu.png&quot; alt=&quot;conda&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;descargar-anaconda&quot;&gt;Descargar anaconda&lt;/h2&gt;

&lt;p&gt;Lo primero que deberas hacer es entrar &lt;a href=&quot;https://www.anaconda.com/products/individual&quot;&gt;aqui&lt;/a&gt; y seleccionar la versión que quieras.&lt;/p&gt;

&lt;p&gt;En mi caso, voy a instalarlo para Ubuntu 20.04 64 bits y python 3.8
https://repo.anaconda.com/archive/Anaconda3-2021.05-Linux-x86_64.sh&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /tmp
&lt;span class=&quot;c&quot;&gt;# descargar&lt;/span&gt;
curl &lt;span class=&quot;nt&quot;&gt;-L&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; anaconda-installer.sh https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.sh
&lt;span class=&quot;c&quot;&gt;# instalar&lt;/span&gt;
bash anaconda-installer.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;En este momento te pedirá leer los términos de licencia, que obviamente deberás aceptar y te mostrará el path por defecto (que podrás cambiar donde se instalará)&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Anaconda3 will now be installed into this location:
/home/enrique/anaconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;/home/enrique/anaconda3] &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;PREFIX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/enrique/anaconda3
Unpacking payload ...
Collecting package metadata &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;current_repodata.json&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: &lt;span class=&quot;k&quot;&gt;done
&lt;/span&gt;Solving environment: &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## Package Plan ##&lt;/span&gt;

  environment location: /home/enrique/anaconda3

  added / updated specs:
    - &lt;span class=&quot;nv&quot;&gt;_ipyw_jlab_nb_ext_conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;0.1.0&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;py37_0
....
y aqui un largo etcétera de librerias ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;una vez acabada la instalación, solo queda añadir el path, que te preguntará&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;installation finished.
Do you wish the installer to prepend the Anaconda3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;location
to PATH &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;your /home/enrique/.bashrc ? &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;yes&lt;/span&gt;|no]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;update-conda&quot;&gt;Update conda&lt;/h2&gt;

&lt;p&gt;Es &lt;strong&gt;altamente recomendable&lt;/strong&gt; actualizar a la última version de conda, que muy probablemente no sea la que se instale con el script anterior. Para actualizar conda en linux&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda update conda
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Fri, 14 May 2021 17:00:00 -0500</pubDate>
      </item>
    
  </channel>
</rss>
