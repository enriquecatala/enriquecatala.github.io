---
layout: post
title:  "Ingestando datos con cabeza"
date:   2022-12-20 00:00:00 +0200
tipue_search_active: true
comments: true
excerpt_separator: <!--end_excerpt-->
tags: Speaker Azure Databricks Kubernetes Cloud Dev AI DataPlatform Performance Speaker YouTube
---

"A few days ago, I had the pleasure and honor of being a speaker at the [NetCoreConf Madrid](https://netcoreconf.com/) event."

Here is the video of my session, I hope you like it:

<iframe width="560" height="315" src="https://www.youtube.com/embed/f3GID7QNY4I?start=26" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<!--end_excerpt-->

This is the abstract of the session:

_Imagine if you could create a data ingestion architecture that allows you to exploit it in real-time or in batch at will, prepared for AI teams (ultra-clean and versioned data), that scales without limits, and where you don't have to worry about cleaning the data because it's literally impossible to ingest garbage. Does it seem impossible to you? Come over, and I'll share some secrets with you :)_
